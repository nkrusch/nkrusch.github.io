<!DOCTYPE html><html><head><meta charSet="utf-8" data-next-head=""/><meta name="viewport" content="width=device-width" data-next-head=""/><meta name="og:title" content="Neea Rusch" data-next-head=""/><meta name="description" content="Homepage" data-next-head=""/><meta name="twitter:card" content="summary_large_image" data-next-head=""/><title data-next-head="">Semantic-preserving optimization algorithm for automatic program parallelization</title><link rel="preload" href="/_next/static/css/a348b42952ae1530.css" as="style"/><link rel="preload" href="/_next/static/css/2d6c8dafa46e2545.css" as="style"/><link rel="stylesheet" href="/_next/static/css/a348b42952ae1530.css" data-n-g=""/><link rel="stylesheet" href="/_next/static/css/2d6c8dafa46e2545.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" noModule="" src="/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/_next/static/chunks/webpack-8cac0b4b405cede1.js" defer=""></script><script src="/_next/static/chunks/framework-b80252dbd720399f.js" defer=""></script><script src="/_next/static/chunks/main-d4c20200ddabac7f.js" defer=""></script><script src="/_next/static/chunks/pages/_app-8b2b478b1c32f058.js" defer=""></script><script src="/_next/static/chunks/855-3e7c581b3f2344af.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bid%5D-ed211a0e33ef7f3d.js" defer=""></script><script src="/_next/static/L6lxukodbHLb6QDxjfoop/_buildManifest.js" defer=""></script><script src="/_next/static/L6lxukodbHLb6QDxjfoop/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="layout_container__jQ1_H"><header class="layout_header__iaASZ"><h2 class="utils_headingLg__RYtYb"><a class="utils_colorInherit__Jz9NS" href="/">Neea Rusch</a></h2> </header><main><article><h1 class="utils_headingXl__zlq1q">Semantic-preserving optimization algorithm for automatic program parallelization</h1><div class="utils_lightText__B_gv3" style="font-size:90%"><time dateTime="2022-04-01">April 1, 2022</time></div><div><p>Presented at Augusta University <a href="https://web.archive.org/web/20240418043248/https://www.augusta.edu/gradschool/grd-2022.php">37th Annual Graduate Research Day</a> (<a href="/files/2022_grd_program.pdf">program</a>) on 1 April 2022. This presentation was recognized with <em>Excellence in Research - Computer &#x26; Cyber Sciences</em> award by The Graduate School.</p></div><div class="abstract"><h3>Abstract</h3><div><p>Advanced and resource-intensive computation relies on continuous rise in processing power. Since the 1970s, Moore's law accurately predicted this growth would be achieved through hardware improvements, but this observation is becoming progressively obsolete. Alternative approaches are needed to maintain increase in efficiency. Parallelization is a technique in which larger computational problem is divided into smaller tasks, which are then executed simultaneously, reducing overall time to completion. Specialized software and algorithms are required to enable parallelization.<br/><br/>This research presents a novel algorithm for automatic program parallelization based on loop splitting. In programming, loop statements are used for carrying out repeated computation, but when used extensively or carelessly, will produce performance inefficiencies. Using a graph-based variable dependency analysis, the algorithm detects opportunities for splitting loops into smaller, parallelizable loops; then automatically applies this optimization. Additionally, the algorithm guarantees the preservation of program semantics post-transformation. We hypothesize this algorithm, when combined with OpenMP--an existing state-of-the-art multiprocessing tool--will provide noticeable performance gains for resource-intensive computational tasks. An open-source tool, pyalp, implementing this algorithm on C programs, is currently being developed to demonstrate and measure its efficiency in practice.</p></div></div><div><h3>Poster</h3><div class="slides ratio_34"><iframe src="../files/grd_poster.pdf#view=FitH"></iframe></div><br/><div><a class="button" href="../files/grd_poster.pdf" target="_blank">Open in new tab</a><span class="button-spacer"></span><a class="button" href="../files/grd_poster.pdf" download="">Download</a></div></div><div></div></article></main><div class="layout_backToHome__uESLU"><a href="/">‚Üê Return</a></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"postData":{"id":"2022-graduate-research-day","contentHtml":null,"title":"Semantic-preserving optimization algorithm for automatic program parallelization","author":"Neea Rusch","date":"2022-04-01","presentation":true,"embed_title":"Poster","embed":"../files/grd_poster.pdf","preface":"\u003cp\u003ePresented at Augusta University \u003ca href=\"https://web.archive.org/web/20240418043248/https://www.augusta.edu/gradschool/grd-2022.php\"\u003e37th Annual Graduate Research Day\u003c/a\u003e (\u003ca href=\"/files/2022_grd_program.pdf\"\u003eprogram\u003c/a\u003e) on 1 April 2022. This presentation was recognized with \u003cem\u003eExcellence in Research - Computer \u0026#x26; Cyber Sciences\u003c/em\u003e award by The Graduate School.\u003c/p\u003e","abstract":"\u003cp\u003eAdvanced and resource-intensive computation relies on continuous rise in processing power. Since the 1970s, Moore's law accurately predicted this growth would be achieved through hardware improvements, but this observation is becoming progressively obsolete. Alternative approaches are needed to maintain increase in efficiency. Parallelization is a technique in which larger computational problem is divided into smaller tasks, which are then executed simultaneously, reducing overall time to completion. Specialized software and algorithms are required to enable parallelization.\nThis research presents a novel algorithm for automatic program parallelization based on loop splitting. In programming, loop statements are used for carrying out repeated computation, but when used extensively or carelessly, will produce performance inefficiencies. Using a graph-based variable dependency analysis, the algorithm detects opportunities for splitting loops into smaller, parallelizable loops; then automatically applies this optimization. Additionally, the algorithm guarantees the preservation of program semantics post-transformation. We hypothesize this algorithm, when combined with OpenMP--an existing state-of-the-art multiprocessing tool--will provide noticeable performance gains for resource-intensive computational tasks. An open-source tool, pyalp, implementing this algorithm on C programs, is currently being developed to demonstrate and measure its efficiency in practice.\u003c/p\u003e","abs_plain":" Advanced and resource-intensive computation relies on continuous rise in processing power. Since the 1970s, Moore's law accurately predicted this growth would be achieved through hardware improvements, but this observation is becoming progressively obsolete. Alternative approaches are needed to maintain increase in efficiency. Parallelization is a technique in which larger computational problem is divided into smaller tasks, which are then executed simultaneously, reducing overall time to completion. Specialized software and algorithms are required to enable parallelization.\nThis research presents a novel algorithm for automatic program parallelization based on loop splitting. In programming, loop statements are used for carrying out repeated computation, but when used extensively or carelessly, will produce performance inefficiencies. Using a graph-based variable dependency analysis, the algorithm detects opportunities for splitting loops into smaller, parallelizable loops; then automatically applies this optimization. Additionally, the algorithm guarantees the preservation of program semantics post-transformation. We hypothesize this algorithm, when combined with OpenMP--an existing state-of-the-art multiprocessing tool--will provide noticeable performance gains for resource-intensive computational tasks. An open-source tool, pyalp, implementing this algorithm on C programs, is currently being developed to demonstrate and measure its efficiency in practice. "},"talkData":{"talks":[{"plas":{"title":"An Information Flow Calculus for Non-Interference","url":"2024-plas","where":"Workshop on Programming Languages and Analysis for Security (PLAS)","when":"2024-10-14","location":"Salt Lake City, Utah","icon":"üá∫üá∏"}},{"aalto":{"title":"Implicit Computational Complexity: From Theory to Practice","url":"2024-aalto","where":"Theoretical Computer Science weekly seminar at Aalto University","when":"2024-08-20","location":"Espoo, Finland","icon":"üá´üáÆ"}},{"atva":{"title":"pymwp: A Static Analyzer Determining Polynomial Growth Bounds","url":"2023-atva","where":"International Symposium on Automated Technology for Verification and Analysis (ATVA)","when":"2023-10-25","location":"Singapore","icon":"üá∏üá¨"}},{"scot":{"title":"mwp-Analysis Improvement and Implementation","url":"2023-scot","where":"SCOT Seminar on Semantic and Formal Approaches to Complexity","when":"2023-03-10","location":"online","icon":"üåê"}},{"coqpl":{"title":"Certifying Complexity Analysis","url":"2023-coqpl","where":"International Workshop on Coq for Programming Languages (CoqPL)","when":"2023-01-21","location":"Boston, Massachusetts","icon":"üá∫üá∏"}},{"vmcai":{"title":"Distributing and Parallelizing Non-canonical Loops","url":"2023-vmcai","where":"International Conference on Verification, Model Checking, and Abstract Interpretation (VMCAI)","when":"2023-01-16","location":"Boston, Massachusetts","icon":"üá∫üá∏"}},{"splash":{"title":"Formally Verified Resource Bounds Through Implicit Computational Complexity","url":"2022-splash","where":"Doctoral Symposium at SPLASH","when":"2022-12-06","location":"Auckland, New Zealand","icon":"üá≥üáø"}},{"types":{"title":"Realizing Implicit Computational Complexity","url":"2022-types","where":"International Conference on Types for Proofs and Programs (TYPES)","when":"2022-06-20","location":"Nantes, France","icon":"üá´üá∑"}},{"grd22":{"title":"Semantic-preserving optimization algorithm for automatic program parallelization","url":"2022-graduate-research-day","where":"The 37th Annual Graduate Research Day at Augusta University","when":"2022-04-01","location":"Augusta, Georgia","icon":"üá∫üá∏"}},{"lipn":{"title":"Implementing the mwp-flow analysis","url":"2021-implementing-the-mwp-flow-analysis","where":"IRISA Rennes and LIPN seminars","when":"2021-11-15","location":"Rennes and Paris, France","icon":"üá´üá∑"}},{"grd21":{"title":"Certifying the complexity and correctness of critical software","url":"2021-graduate-research-day","where":"The 36th Annual Graduate Research Day at Augusta University","when":"2021-03-31","location":"online","icon":"üåê"}}]}},"__N_SSG":true},"page":"/posts/[id]","query":{"id":"2022-graduate-research-day"},"buildId":"L6lxukodbHLb6QDxjfoop","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>